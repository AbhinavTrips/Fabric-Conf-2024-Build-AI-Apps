{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup, Vectorize and Load Data\n",
    "\n",
    "In this tutorial, we'll demonstrate how to leverage a sample dataset stored in Azure Cosmos DB for MongoDB vCore to ground OpenAI models. We'll do this taking advantage of Azure Cosmos DB for MongoDB [vector similarity search](https://learn.microsoft.com/azure/cosmos-db/mongodb/vcore/vector-search) functionality. In the end, we'll create an interatice chat session with the GPT  completions model to answer questions about Azure services informed by our dataset. This process is known as Retrieval Augmented Generation, or RAG.\n",
    "\n",
    "The source data for this demo is the Movie Lens dataset which contains a subset of data on movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai\n",
    "! pip install pymongo\n",
    "! pip install python-dotenv\n",
    "! pip install ijson\n",
    "! pip install urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import ijson\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import dotenv_values\n",
    "import urllib\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment values and intantiate clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"fabcondemo.env\" # following example.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "mongo_conn = config['mongo_connection_string']\n",
    "mongo_database = config['mongo_database_name']\n",
    "mongo_collection = config['mongo_collection_name']\n",
    "mongo_vector_property = config['mongo_vector_property_name']\n",
    "mongo_cache = config['mongo_cache_collection_name']\n",
    "# Create the MongoDB client\n",
    "mongo_client = pymongo.MongoClient(mongo_conn)\n",
    "\n",
    "storage_file_url = config['storage_file_url']\n",
    "\n",
    "openai_endpoint = config['openai_endpoint']\n",
    "openai_key = config['openai_key']\n",
    "openai_version = config['openai_version']\n",
    "openai_embeddings_deployment = config['openai_embeddings_deployment']\n",
    "openai_embeddings_model = config['openai_embeddings_model']\n",
    "openai_embeddings_dimensions = int(config['openai_embeddings_dimensions'])\n",
    "openai_completions_deployment = config['openai_completions_deployment']\n",
    "openai_completions_model = config['openai_completions_model']\n",
    "# Create the OpenAI client\n",
    "openai_client = AzureOpenAI(azure_endpoint=openai_endpoint, api_key=openai_key, api_version=openai_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define a function to create a collection with a vector index\n",
    "\n",
    "Define a function to create a new collection with a vector index. This function takes a database object, a collection name, the name of a document property that will store vectors, and the number of vector dimensions used for the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection_and_vector_index(database, mongo_collection, vector_property, embeddings_dimensions):\n",
    "\n",
    "    collection = database[mongo_collection]\n",
    "\n",
    "    ## Rewrite the collection and index creation\n",
    "    database.command(\n",
    "    {\n",
    "        \"createIndexes\": mongo_collection,\n",
    "        \"indexes\": [\n",
    "            {\n",
    "                \"name\": \"VectorSearchIndex\",\n",
    "                \"key\": {\n",
    "                    vector_property: \"cosmosSearch\"\n",
    "                },\n",
    "                \"cosmosSearchOptions\": { \n",
    "                    \"kind\": \"vector-hnsw\", \n",
    "                    \"m\": 16, # default value \n",
    "                    \"efConstruction\": 64, # default value \n",
    "                    \"similarity\": \"COS\", \n",
    "                    \"dimensions\": embeddings_dimensions\n",
    "                } \n",
    "            } \n",
    "        ] \n",
    "    }\n",
    "    )\n",
    "\n",
    "    return collection\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MongoDB Database and Collections with Vector Index\n",
    "\n",
    "Create a collection for the data and another as a conversation cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the collection database and drop if it does\n",
    "if mongo_database in mongo_client.list_database_names():\n",
    "    mongo_client.drop_database(mongo_database)\n",
    "\n",
    "# Create the database FabConfDB\n",
    "database = mongo_client[mongo_database]\n",
    "\n",
    "# Create the data collection with vector index\n",
    "collection = create_collection_and_vector_index(database, mongo_collection, mongo_vector_property, openai_embeddings_dimensions)\n",
    "\n",
    "# Create the cache collection with vector index\n",
    "cache = create_collection_and_vector_index(database, mongo_cache, mongo_vector_property, openai_embeddings_dimensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to generate embeddings from Azure OpenAI\n",
    "\n",
    "Generate embeddings from passed in string. Add retry to handle any throttling due to quota limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=200), stop=stop_after_attempt(20))\n",
    "def generate_embeddings(text):\n",
    "    '''\n",
    "    Generate embeddings from string of text.\n",
    "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
    "    '''\n",
    "\n",
    "    ## Rewrite the embeddings creation\n",
    "\n",
    "    # OpenAI asks for a model in parameters here but it's actually a deployment.\n",
    "    response = openai_client.embeddings.create(\n",
    "        input = text, \n",
    "        model = openai_embeddings_deployment, \n",
    "        dimensions = openai_embeddings_dimensions)\n",
    "    \n",
    "    #sleep(.1)\n",
    "    \n",
    "    embeddings = response.model_dump()\n",
    "    return embeddings['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest, vectorize & store\n",
    "\n",
    "Read the data out of blob storage, generate vectors on it, then store in Azure Cosmos DB for MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file and stream the data to ingest\n",
    "stream = urllib.request.urlopen(storage_file_url)\n",
    "\n",
    "success = True\n",
    "counter = 0\n",
    "\n",
    "# iterate through the stream, generate vectors and insert into collection\n",
    "for object in ijson.items(stream, 'item', use_float=True):\n",
    "\n",
    "    ## Rewrite the data vectorization and ingestion\n",
    "\n",
    "    # generate an embedding for each overview to add to vector index\n",
    "    vectorArray = generate_embeddings(object['overview'])\n",
    "\n",
    "    # add the embedding to the JSON document\n",
    "    object[mongo_vector_property] = vectorArray\n",
    "\n",
    "    # insert the document into the collection\n",
    "    collection.insert_one(object)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    if counter % 100 == 0:\n",
    "        print(\"Inserted {} documents into collection: '{}'.\".format(counter, collection.name))\n",
    "        sleep(.5)\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Data inserted into collection: '{}'.\\n\".format(collection.name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
